{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the training and test set used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#load the training dataset\n",
    "datasub = pd.read_pickle('Training_Set_Processed_new_topK_v2.pkl')\n",
    "#load the test dataset\n",
    "datasub_test = pd.read_pickle('Test_Set_Processed_new_topK_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prod_smiles</th>\n",
       "      <th>rxn_smiles</th>\n",
       "      <th>atom mapped smiles-input</th>\n",
       "      <th>not atom mapped smiles-input</th>\n",
       "      <th>dataset</th>\n",
       "      <th>template</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15154</td>\n",
       "      <td>O=C([O-])c1ccc(O[C@@H]2O[C@H](CO)[C@@H](O)[C@H...</td>\n",
       "      <td>O=c1ccn([C@@H]2O[C@H](COP(=O)([O-])OP(=O)([O-]...</td>\n",
       "      <td>[[O:11]=[c:12]1[cH:13][cH:14][n:15]([C@@H:16]2...</td>\n",
       "      <td>O=C([O-])C1=CC=C(O)C=C1.O=C1C=CN([C@@H]2O[C@H]...</td>\n",
       "      <td>train</td>\n",
       "      <td>([#8:2]-[C@H;D3;+0:1](-[C:3])-[O;H0;D2;+0:4]-[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50174</td>\n",
       "      <td>CCCCC/C=C\\C/C=C\\C/C=C\\C/C=C\\CCCC(=O)N[C@@H](C)...</td>\n",
       "      <td>OO[C@@H:9]([CH2:8]/[CH:7]=[CH:6]\\[CH2:5][CH2:4...</td>\n",
       "      <td>[[CH3:1][CH2:2][CH2:3][CH2:4][CH2:5]/[CH:6]=[C...</td>\n",
       "      <td>CCCCC/C=C\\C[C@@H](/C=C/C=C\\C/C=C\\CCCC(=O)N[C@@...</td>\n",
       "      <td>train</td>\n",
       "      <td>([C:9]/[C:8]=[C:7]\\[CH2;D2;+0:6]/[CH;D2;+0:5]=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37517</td>\n",
       "      <td>CCCCCCCCCCCC(=O)SCCNC(=O)CCNC(=O)[C@H](O)C(C)(...</td>\n",
       "      <td>CCCCCCCCCCCCCCCC(=O)OC[C@H](COP(=O)([O-])OCC[N...</td>\n",
       "      <td>[[CH3:1][CH2:2][CH2:3][CH2:4][CH2:5][CH2:6][CH...</td>\n",
       "      <td>CC(C)(COP(=O)([O-])OP(=O)([O-])OC[C@H]1O[C@@H]...</td>\n",
       "      <td>train</td>\n",
       "      <td>([C:2]-[C;H0;D3;+0:1](=[O;D1;H0:3])-[S;H0;D2;+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19366</td>\n",
       "      <td>O=C(COP(=O)([O-])[O-])[C@H](O)[C@H](O)COP(=O)(...</td>\n",
       "      <td>Nc1ncnc2c1ncn2[C@@H]1O[C@H](COP(=O)([O-])O[P:2...</td>\n",
       "      <td>[[NH2:1][c:2]1[n:3][cH:4][n:5][c:6]2[c:7]1[n:8...</td>\n",
       "      <td>NC1=NC=NC2=C1N=CN2[C@@H]1O[C@H](COP(=O)([O-])O...</td>\n",
       "      <td>train</td>\n",
       "      <td>([O-;H0;D1:4]-[P;H0;D4;+0:1](-[O;-;D1;H0:2])(=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57589</td>\n",
       "      <td>O=C1C[C@@](O)(c2ccc(O)cc2)Oc2cc(O)cc(O)c21</td>\n",
       "      <td>[O:32]=[C:33]1[CH2:34][C@@H:35]([c:36]2[cH:37]...</td>\n",
       "      <td>[[CH3:1][c:2]1[cH:3][c:4]2[c:5]([cH:6][c:7]1[C...</td>\n",
       "      <td>CC1=C(C)C=C2C(=C1)NC1=C(NC(=O)NC1=O)N2C[C@H](O...</td>\n",
       "      <td>train</td>\n",
       "      <td>([#8:2]-[C@;H0;D4;+0:3](-[OH;D1;+0:1])(-[c:4])...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        prod_smiles  \\\n",
       "1  15154  O=C([O-])c1ccc(O[C@@H]2O[C@H](CO)[C@@H](O)[C@H...   \n",
       "2  50174  CCCCC/C=C\\C/C=C\\C/C=C\\C/C=C\\CCCC(=O)N[C@@H](C)...   \n",
       "3  37517  CCCCCCCCCCCC(=O)SCCNC(=O)CCNC(=O)[C@H](O)C(C)(...   \n",
       "4  19366  O=C(COP(=O)([O-])[O-])[C@H](O)[C@H](O)COP(=O)(...   \n",
       "5  57589         O=C1C[C@@](O)(c2ccc(O)cc2)Oc2cc(O)cc(O)c21   \n",
       "\n",
       "                                          rxn_smiles  \\\n",
       "1  O=c1ccn([C@@H]2O[C@H](COP(=O)([O-])OP(=O)([O-]...   \n",
       "2  OO[C@@H:9]([CH2:8]/[CH:7]=[CH:6]\\[CH2:5][CH2:4...   \n",
       "3  CCCCCCCCCCCCCCCC(=O)OC[C@H](COP(=O)([O-])OCC[N...   \n",
       "4  Nc1ncnc2c1ncn2[C@@H]1O[C@H](COP(=O)([O-])O[P:2...   \n",
       "5  [O:32]=[C:33]1[CH2:34][C@@H:35]([c:36]2[cH:37]...   \n",
       "\n",
       "                            atom mapped smiles-input  \\\n",
       "1  [[O:11]=[c:12]1[cH:13][cH:14][n:15]([C@@H:16]2...   \n",
       "2  [[CH3:1][CH2:2][CH2:3][CH2:4][CH2:5]/[CH:6]=[C...   \n",
       "3  [[CH3:1][CH2:2][CH2:3][CH2:4][CH2:5][CH2:6][CH...   \n",
       "4  [[NH2:1][c:2]1[n:3][cH:4][n:5][c:6]2[c:7]1[n:8...   \n",
       "5  [[CH3:1][c:2]1[cH:3][c:4]2[c:5]([cH:6][c:7]1[C...   \n",
       "\n",
       "                        not atom mapped smiles-input dataset  \\\n",
       "1  O=C([O-])C1=CC=C(O)C=C1.O=C1C=CN([C@@H]2O[C@H]...   train   \n",
       "2  CCCCC/C=C\\C[C@@H](/C=C/C=C\\C/C=C\\CCCC(=O)N[C@@...   train   \n",
       "3  CC(C)(COP(=O)([O-])OP(=O)([O-])OC[C@H]1O[C@@H]...   train   \n",
       "4  NC1=NC=NC2=C1N=CN2[C@@H]1O[C@H](COP(=O)([O-])O...   train   \n",
       "5  CC1=C(C)C=C2C(=C1)NC1=C(NC(=O)NC1=O)N2C[C@H](O...   train   \n",
       "\n",
       "                                            template  \n",
       "1  ([#8:2]-[C@H;D3;+0:1](-[C:3])-[O;H0;D2;+0:4]-[...  \n",
       "2  ([C:9]/[C:8]=[C:7]\\[CH2;D2;+0:6]/[CH;D2;+0:5]=...  \n",
       "3  ([C:2]-[C;H0;D3;+0:1](=[O;D1;H0:3])-[S;H0;D2;+...  \n",
       "4  ([O-;H0;D1:4]-[P;H0;D4;+0:1](-[O;-;D1;H0:2])(=...  \n",
       "5  ([#8:2]-[C@;H0;D4;+0:3](-[OH;D1;+0:1])(-[c:4])...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prod_smiles</th>\n",
       "      <th>rxn_smiles</th>\n",
       "      <th>atom mapped smiles-input</th>\n",
       "      <th>not atom mapped smiles-input</th>\n",
       "      <th>dataset</th>\n",
       "      <th>prec_goal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20342</td>\n",
       "      <td>O=P([O-])([O-])OC[C@H](O)CO[C@H]1O[C@H](CO)[C@...</td>\n",
       "      <td>O=c1ccn([C@@H]2O[C@H](COP(=O)([O-])OP(=O)([O-]...</td>\n",
       "      <td>[[O:11]=[c:12]1[cH:13][cH:14][n:15]([C@@H:16]2...</td>\n",
       "      <td>O=C1C=CN([C@@H]2O[C@H](COP(=O)([O-])OP(=O)([O-...</td>\n",
       "      <td>test</td>\n",
       "      <td>[O=P([O-])([O-])OC[C@H](O)CO.O=c1ccn([C@@H]2O[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50829</td>\n",
       "      <td>CCCCC[C@@H](/C=C/C=C\\C/C=C\\C/C=C\\C/C=C\\CCC(=O)...</td>\n",
       "      <td>[CH3:1][CH2:2][CH2:3][CH2:4][CH2:5]/[CH:6]=[CH...</td>\n",
       "      <td>[[CH3:1][CH2:2][CH2:3][CH2:4][CH2:5]/[CH:6]=[C...</td>\n",
       "      <td>CCCCC/C=C\\C/C=C\\C/C=C\\C/C=C\\C/C=C\\CCC(=O)[O-]....</td>\n",
       "      <td>test</td>\n",
       "      <td>[CCCCC/C=C\\C/C=C\\C/C=C\\C/C=C\\C/C=C\\CCC(=O)[O-]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52285</td>\n",
       "      <td>CCCCC/C=C\\C(O)/C=C\\CCCCCCCC(=O)[O-]</td>\n",
       "      <td>[CH3:1][CH2:2][CH2:3][CH2:4][CH2:5]/[CH:6]=[CH...</td>\n",
       "      <td>[[CH3:1][CH2:2][CH2:3][CH2:4][CH2:5]/[CH:6]=[C...</td>\n",
       "      <td>CC1=C(C)C=C2C(=C1)NC1=C(NC(=O)NC1=O)N2C[C@H](O...</td>\n",
       "      <td>test</td>\n",
       "      <td>[CCCCC/C=C\\C/C=C\\CCCCCCCC(=O)[O-].O=O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37172</td>\n",
       "      <td>CCCCCCCC/C=C\\CCCCCCCC(=O)OC[C@H](COP(=O)([O-])...</td>\n",
       "      <td>[CH3:1][CH2:2][CH2:3][CH2:4][CH2:5][CH2:6][CH2...</td>\n",
       "      <td>[[CH3:1][CH2:2][CH2:3][CH2:4][CH2:5][CH2:6][CH...</td>\n",
       "      <td>CCCCCCCC/C=C\\CCCCCCCC(=O)OC[C@@H](O)COP(=O)([O...</td>\n",
       "      <td>test</td>\n",
       "      <td>[CCCCCCCC/C=C\\CCCCCCCC(=O)OC[C@@H](O)COP(=O)([...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44874</td>\n",
       "      <td>CCCCCCCCCCCCCCCC(=O)OC[C@H](COP(=O)([O-])OCC[N...</td>\n",
       "      <td>[O-][P:23]([O:22][CH2:21][C@@H:20]([CH2:19][O:...</td>\n",
       "      <td>[[CH3:1][CH2:2][CH2:3][CH2:4][CH2:5][CH2:6][CH...</td>\n",
       "      <td>CCCCCCCCCCCCCCCC(=O)OC[C@H](COP(=O)([O-])[O-])...</td>\n",
       "      <td>test</td>\n",
       "      <td>[CCCCCCCCCCCCCCCC(=O)OC[C@H](COP(=O)([O-])[O-]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        prod_smiles  \\\n",
       "0  20342  O=P([O-])([O-])OC[C@H](O)CO[C@H]1O[C@H](CO)[C@...   \n",
       "1  50829  CCCCC[C@@H](/C=C/C=C\\C/C=C\\C/C=C\\C/C=C\\CCC(=O)...   \n",
       "2  52285                CCCCC/C=C\\C(O)/C=C\\CCCCCCCC(=O)[O-]   \n",
       "3  37172  CCCCCCCC/C=C\\CCCCCCCC(=O)OC[C@H](COP(=O)([O-])...   \n",
       "4  44874  CCCCCCCCCCCCCCCC(=O)OC[C@H](COP(=O)([O-])OCC[N...   \n",
       "\n",
       "                                          rxn_smiles  \\\n",
       "0  O=c1ccn([C@@H]2O[C@H](COP(=O)([O-])OP(=O)([O-]...   \n",
       "1  [CH3:1][CH2:2][CH2:3][CH2:4][CH2:5]/[CH:6]=[CH...   \n",
       "2  [CH3:1][CH2:2][CH2:3][CH2:4][CH2:5]/[CH:6]=[CH...   \n",
       "3  [CH3:1][CH2:2][CH2:3][CH2:4][CH2:5][CH2:6][CH2...   \n",
       "4  [O-][P:23]([O:22][CH2:21][C@@H:20]([CH2:19][O:...   \n",
       "\n",
       "                            atom mapped smiles-input  \\\n",
       "0  [[O:11]=[c:12]1[cH:13][cH:14][n:15]([C@@H:16]2...   \n",
       "1  [[CH3:1][CH2:2][CH2:3][CH2:4][CH2:5]/[CH:6]=[C...   \n",
       "2  [[CH3:1][CH2:2][CH2:3][CH2:4][CH2:5]/[CH:6]=[C...   \n",
       "3  [[CH3:1][CH2:2][CH2:3][CH2:4][CH2:5][CH2:6][CH...   \n",
       "4  [[CH3:1][CH2:2][CH2:3][CH2:4][CH2:5][CH2:6][CH...   \n",
       "\n",
       "                        not atom mapped smiles-input dataset  \\\n",
       "0  O=C1C=CN([C@@H]2O[C@H](COP(=O)([O-])OP(=O)([O-...    test   \n",
       "1  CCCCC/C=C\\C/C=C\\C/C=C\\C/C=C\\C/C=C\\CCC(=O)[O-]....    test   \n",
       "2  CC1=C(C)C=C2C(=C1)NC1=C(NC(=O)NC1=O)N2C[C@H](O...    test   \n",
       "3  CCCCCCCC/C=C\\CCCCCCCC(=O)OC[C@@H](O)COP(=O)([O...    test   \n",
       "4  CCCCCCCCCCCCCCCC(=O)OC[C@H](COP(=O)([O-])[O-])...    test   \n",
       "\n",
       "                                           prec_goal  \n",
       "0  [O=P([O-])([O-])OC[C@H](O)CO.O=c1ccn([C@@H]2O[...  \n",
       "1  [CCCCC/C=C\\C/C=C\\C/C=C\\C/C=C\\C/C=C\\CCC(=O)[O-]...  \n",
       "2             [CCCCC/C=C\\C/C=C\\CCCCCCCC(=O)[O-].O=O]  \n",
       "3  [CCCCCCCC/C=C\\CCCCCCCC(=O)OC[C@@H](O)COP(=O)([...  \n",
       "4  [CCCCCCCCCCCCCCCC(=O)OC[C@H](COP(=O)([O-])[O-]...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasub_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add fingerprint information to the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [12:43:05] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "# import all necessary packages\n",
    "import rdkit.Chem as Chem\n",
    "import rdkit.Chem.AllChem as AllChem\n",
    "from rdkit import DataStructs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up fingerprinting of molecules\n",
    "getfp = lambda smi: AllChem.GetMorganFingerprint(Chem.MolFromSmiles(smi),2,useChirality=True, useFeatures=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up similarity label\n",
    "similarity_metric = DataStructs.BulkDiceSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets Morgan Fingerprints for all products in the training set\n",
    "all_fps_train = []\n",
    "\n",
    "for smi in datasub['prod_smiles']:\n",
    "    all_fps_train.append(getfp(smi))\n",
    "\n",
    "#Append the fingerprints of all products\n",
    "datasub['prod_fp'] = all_fps_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets Morgan Fingerprints for all products in the test set\n",
    "all_fps_test = []\n",
    "\n",
    "for smi in datasub_test['prod_smiles']:\n",
    "    all_fps_test.append(getfp(smi))\n",
    "\n",
    "#Append the fingerprints of all products\n",
    "datasub_test['prod_fp'] = all_fps_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrosynthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#template extraction and application corresponding to enzymes\n",
    "from template_extractor_enz_v4 import extract_from_reaction\n",
    "from main_v3 import rdchiralRun\n",
    "#import all other modules\n",
    "from rdchiral.initialization import rdchiralReaction, rdchiralReactants\n",
    "from rdkit import DataStructs\n",
    "import numpy as np\n",
    "import rdkit.Chem as Chem\n",
    "import rdkit.Chem.AllChem as AllChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_one(similarity_label, getfp_label, datasub, datasub_test_ix, max_prec=40):\n",
    "\n",
    "    #setup a similarity metric\n",
    "    if similarity_label == 'Tanimoto':\n",
    "        similarity_metric = DataStructs.BulkTanimotoSimilarity\n",
    "    elif similarity_label == 'Dice':\n",
    "        similarity_metric = DataStructs.BulkDiceSimilarity\n",
    "    elif similarity_label == 'TverskyA': # weighted towards punishing onlyA\n",
    "        def similarity_metric(x, y):\n",
    "            return DataStructs.BulkTverskySimilarity(x, y, 1.5, 1.0)\n",
    "    elif similarity_label == 'TverskyB': # weighted towards punishing onlyB\n",
    "        def similarity_metric(x, y):\n",
    "            return DataStructs.BulkTverskySimilarity(x, y, 1.0, 1.5)\n",
    "    else:\n",
    "        raise ValueError('Unknown similarity label')\n",
    "\n",
    "    #set fingerprint type    \n",
    "    if getfp_label == 'Morgan2noFeat':\n",
    "        getfp = lambda smi: AllChem.GetMorganFingerprint(Chem.MolFromSmiles(smi), 2, useFeatures=False, useChirality = True)\n",
    "    elif getfp_label == 'Morgan3noFeat':\n",
    "        getfp = lambda smi: AllChem.GetMorganFingerprint(Chem.MolFromSmiles(smi), 3, useFeatures=False, useChirality = True)\n",
    "    elif getfp_label == 'Morgan2Feat':\n",
    "        getfp = lambda smi: AllChem.GetMorganFingerprint(Chem.MolFromSmiles(smi), 2, useFeatures=True, useChirality = True)\n",
    "    elif getfp_label == 'Morgan3Feat':\n",
    "        getfp = lambda smi: AllChem.GetMorganFingerprint(Chem.MolFromSmiles(smi), 3, useFeatures=True, useChirality = True)\n",
    "    else:\n",
    "        raise ValueError('Unknown getfp label')\n",
    "        \n",
    "    #loads product SMILES into RDChiral object    \n",
    "    rct = rdchiralReactants(datasub_test_ix['prod_smiles'])\n",
    "    \n",
    "    #get the fingerprint of the product\n",
    "    fp = datasub_test_ix['prod_fp']\n",
    "    \n",
    "    #calculates similarity metric between fingerprint \n",
    "    # and all fingerprints in the database\n",
    "    sims = similarity_metric (fp, [fp_ for fp_ in datasub['prod_fp']])\n",
    "    \n",
    "    #sort the similarity metric in reverse order\n",
    "    js = np.argsort(sims) [::-1]\n",
    "    \n",
    "    #get prec_goal from the test dataframe\n",
    "    prec_goal = datasub_test_ix['prec_goal']\n",
    "        \n",
    "    # Get probability of precursors\n",
    "    probs = {}\n",
    "    \n",
    "    for ji,j in enumerate (js[:max_prec]):\n",
    "        jx = datasub.index[j]\n",
    "\n",
    "        template=datasub['template'][jx]\n",
    "                \n",
    "        #get rcts reference fingerprint\n",
    "        rcts_ref_fp = getfp(datasub['rxn_smiles'][jx].split('>')[0])        \n",
    "        \n",
    "        try:\n",
    "            rxn = rdchiralReaction(template)\n",
    "        except:\n",
    "            continue \n",
    "        \n",
    "        try:\n",
    "            outcomes = rdchiralRun(rxn, rct, combine_enantiomers=False)\n",
    "        \n",
    "        except:\n",
    "            outcomes = []\n",
    "            \n",
    "        for precursors in outcomes:\n",
    "            precursors_fp = getfp(precursors)\n",
    "            precursors_sim = similarity_metric(precursors_fp, [rcts_ref_fp])[0]\n",
    "            if precursors in probs:\n",
    "                probs[precursors] = max(probs[precursors], precursors_sim * sims[j])\n",
    "            else:\n",
    "                probs[precursors] = precursors_sim * sims[j]\n",
    "    \n",
    "    found_rank = 9999\n",
    "    \n",
    "    for r, (prec, prob) in enumerate(sorted(probs.items(), key=lambda x:x[1], reverse=True)[:]):      \n",
    "        if prec in prec_goal:\n",
    "            found_rank = min(found_rank,r + 1)\n",
    "    \n",
    "    return found_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "getfp_label = 'Morgan2Feat'\n",
    "similarity_label = 'Dice'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run top-k accuracy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=25)]: Using backend LokyBackend with 25 concurrent workers.\n",
      "[Parallel(n_jobs=25)]: Done 150 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=25)]: Done 400 tasks      | elapsed:   48.7s\n",
      "[Parallel(n_jobs=25)]: Done 698 out of 698 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "results1=Parallel(n_jobs=25, verbose=1)(delayed(do_one) (similarity_label, getfp_label, datasub, datasub_test.iloc[ix]) for ix in datasub_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=25)]: Using backend LokyBackend with 25 concurrent workers.\n",
      "[Parallel(n_jobs=25)]: Done 150 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=25)]: Done 400 tasks      | elapsed:   50.0s\n",
      "[Parallel(n_jobs=25)]: Done 698 out of 698 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "results2=Parallel(n_jobs=25, verbose=1)(delayed(do_one) (similarity_label, getfp_label, datasub, datasub_test.iloc[ix]) for ix in datasub_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=25)]: Using backend LokyBackend with 25 concurrent workers.\n",
      "[Parallel(n_jobs=25)]: Done 150 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=25)]: Done 400 tasks      | elapsed:   49.0s\n",
      "[Parallel(n_jobs=25)]: Done 698 out of 698 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "results3=Parallel(n_jobs=25, verbose=1)(delayed(do_one) (similarity_label, getfp_label, datasub, datasub_test.iloc[ix]) for ix in datasub_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranks_to_acc(found_at_rank, fid=None):\n",
    "    def fprint(txt):\n",
    "        print(txt)\n",
    "        if fid is not None:\n",
    "            fid.write(txt + '\\n')\n",
    "            \n",
    "    tot = float(len(found_at_rank))\n",
    "    fprint('{:>8} \\t {:>8}'.format('top-n', 'accuracy'))\n",
    "    accs = []\n",
    "    for n in [1, 3, 5, 10, 20, 50, 100]:\n",
    "        accs.append(sum([r <= n for r in found_at_rank]) / tot)\n",
    "        fprint('{:>8} \\t {:>8}'.format(n, accs[-1]))\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   top-n \t accuracy\n",
      "       1 \t 0.17335243553008595\n",
      "       3 \t 0.3868194842406877\n",
      "       5 \t 0.505730659025788\n",
      "      10 \t 0.7077363896848138\n",
      "      20 \t 0.8581661891117478\n",
      "      50 \t 0.8724928366762178\n",
      "     100 \t 0.8724928366762178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17335243553008595,\n",
       " 0.3868194842406877,\n",
       " 0.505730659025788,\n",
       " 0.7077363896848138,\n",
       " 0.8581661891117478,\n",
       " 0.8724928366762178,\n",
       " 0.8724928366762178]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks_to_acc(results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   top-n \t accuracy\n",
      "       1 \t 0.167621776504298\n",
      "       3 \t 0.38968481375358166\n",
      "       5 \t 0.5071633237822349\n",
      "      10 \t 0.7106017191977078\n",
      "      20 \t 0.8581661891117478\n",
      "      50 \t 0.8724928366762178\n",
      "     100 \t 0.8724928366762178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.167621776504298,\n",
       " 0.38968481375358166,\n",
       " 0.5071633237822349,\n",
       " 0.7106017191977078,\n",
       " 0.8581661891117478,\n",
       " 0.8724928366762178,\n",
       " 0.8724928366762178]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks_to_acc(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   top-n \t accuracy\n",
      "       1 \t 0.17335243553008595\n",
      "       3 \t 0.38825214899713467\n",
      "       5 \t 0.5071633237822349\n",
      "      10 \t 0.7091690544412608\n",
      "      20 \t 0.8581661891117478\n",
      "      50 \t 0.8724928366762178\n",
      "     100 \t 0.8724928366762178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17335243553008595,\n",
       " 0.38825214899713467,\n",
       " 0.5071633237822349,\n",
       " 0.7091690544412608,\n",
       " 0.8581661891117478,\n",
       " 0.8724928366762178,\n",
       " 0.8724928366762178]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks_to_acc(results3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_one_random(similarity_label, getfp_label, datasub, datasub_test_ix, max_prec=40):\n",
    "\n",
    "    #setup a similarity metric\n",
    "    if similarity_label == 'Tanimoto':\n",
    "        similarity_metric = DataStructs.BulkTanimotoSimilarity\n",
    "    elif similarity_label == 'Dice':\n",
    "        similarity_metric = DataStructs.BulkDiceSimilarity\n",
    "    elif similarity_label == 'TverskyA': # weighted towards punishing onlyA\n",
    "        def similarity_metric(x, y):\n",
    "            return DataStructs.BulkTverskySimilarity(x, y, 1.5, 1.0)\n",
    "    elif similarity_label == 'TverskyB': # weighted towards punishing onlyB\n",
    "        def similarity_metric(x, y):\n",
    "            return DataStructs.BulkTverskySimilarity(x, y, 1.0, 1.5)\n",
    "    else:\n",
    "        raise ValueError('Unknown similarity label')\n",
    "\n",
    "    #set fingerprint type    \n",
    "    if getfp_label == 'Morgan2noFeat':\n",
    "        getfp = lambda smi: AllChem.GetMorganFingerprint(Chem.MolFromSmiles(smi), 2, useFeatures=False, useChirality = True)\n",
    "    elif getfp_label == 'Morgan3noFeat':\n",
    "        getfp = lambda smi: AllChem.GetMorganFingerprint(Chem.MolFromSmiles(smi), 3, useFeatures=False, useChirality = True)\n",
    "    elif getfp_label == 'Morgan2Feat':\n",
    "        getfp = lambda smi: AllChem.GetMorganFingerprint(Chem.MolFromSmiles(smi), 2, useFeatures=True, useChirality = True)\n",
    "    elif getfp_label == 'Morgan3Feat':\n",
    "        getfp = lambda smi: AllChem.GetMorganFingerprint(Chem.MolFromSmiles(smi), 3, useFeatures=True, useChirality = True)\n",
    "    else:\n",
    "        raise ValueError('Unknown getfp label')\n",
    "        \n",
    "    #loads product SMILES into RDChiral object    \n",
    "    rct = rdchiralReactants(datasub_test_ix['prod_smiles'])\n",
    "    \n",
    "    #randomly select max_prec indeces\n",
    "    random_rxns = datasub.sample(n=max_prec).index.tolist()\n",
    "    \n",
    "    #get prec_goal from the test dataframe\n",
    "    prec_goal = datasub_test_ix['prec_goal']\n",
    "        \n",
    "    # Get probability of precursors\n",
    "    probs = []\n",
    "    \n",
    "    for index in random_rxns:\n",
    "        \n",
    "        #get index\n",
    "        jx = index\n",
    "        \n",
    "        #get template\n",
    "        template=datasub['template'][jx]     \n",
    "        \n",
    "        #load it into the rdchiral reaction\n",
    "        try:\n",
    "            rxn = rdchiralReaction(template)\n",
    "        except:\n",
    "            continue \n",
    "        \n",
    "        #try to run the reaction\n",
    "        try:\n",
    "            outcomes = rdchiralRun(rxn, rct, combine_enantiomers=False)\n",
    "        \n",
    "        except:\n",
    "            outcomes = []\n",
    "        \n",
    "        #if there are outcomes->plans in probs list\n",
    "        for precursors in outcomes:\n",
    "            probs.append ([precursors, jx])\n",
    "    \n",
    "    found_rank = 9999\n",
    "    \n",
    "    #shuffle randomly to rank\n",
    "    random.shuffle (probs)\n",
    "    \n",
    "    #parse through the ranked results\n",
    "    for r, solution in enumerate(probs):      \n",
    "        if solution[0] in prec_goal:\n",
    "            found_rank = min(found_rank,r + 1)\n",
    "    \n",
    "    #return found rank\n",
    "    return found_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run three replicates to get mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=25)]: Using backend LokyBackend with 25 concurrent workers.\n",
      "[Parallel(n_jobs=25)]: Done 150 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=25)]: Done 400 tasks      | elapsed:   47.9s\n",
      "[Parallel(n_jobs=25)]: Done 698 out of 698 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "results_random = Parallel(n_jobs=25, verbose=1)(delayed(do_one_random) (similarity_label, getfp_label, datasub, datasub_test.iloc[ix]) for ix in datasub_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   top-n \t accuracy\n",
      "       1 \t 0.03008595988538682\n",
      "       3 \t 0.07736389684813753\n",
      "       5 \t 0.12320916905444126\n",
      "      10 \t 0.17621776504297995\n",
      "      20 \t 0.20773638968481375\n",
      "      50 \t 0.22349570200573066\n",
      "     100 \t 0.22349570200573066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03008595988538682,\n",
       " 0.07736389684813753,\n",
       " 0.12320916905444126,\n",
       " 0.17621776504297995,\n",
       " 0.20773638968481375,\n",
       " 0.22349570200573066,\n",
       " 0.22349570200573066]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks_to_acc(results_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=25)]: Using backend LokyBackend with 25 concurrent workers.\n",
      "[Parallel(n_jobs=25)]: Done 150 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=25)]: Done 400 tasks      | elapsed:   48.6s\n",
      "[Parallel(n_jobs=25)]: Done 698 out of 698 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "results_random_2 = Parallel(n_jobs=25, verbose=1)(delayed(do_one_random) (similarity_label, getfp_label, datasub, datasub_test.iloc[ix]) for ix in datasub_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   top-n \t accuracy\n",
      "       1 \t 0.04871060171919771\n",
      "       3 \t 0.1017191977077364\n",
      "       5 \t 0.14469914040114612\n",
      "      10 \t 0.1977077363896848\n",
      "      20 \t 0.23065902578796563\n",
      "      50 \t 0.23782234957020057\n",
      "     100 \t 0.23782234957020057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04871060171919771,\n",
       " 0.1017191977077364,\n",
       " 0.14469914040114612,\n",
       " 0.1977077363896848,\n",
       " 0.23065902578796563,\n",
       " 0.23782234957020057,\n",
       " 0.23782234957020057]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks_to_acc(results_random_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=25)]: Using backend LokyBackend with 25 concurrent workers.\n",
      "[Parallel(n_jobs=25)]: Done 150 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=25)]: Done 400 tasks      | elapsed:   50.6s\n",
      "[Parallel(n_jobs=25)]: Done 698 out of 698 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "results_random_3 = Parallel(n_jobs=25, verbose=1)(delayed(do_one_random) (similarity_label, getfp_label, datasub, datasub_test.iloc[ix]) for ix in datasub_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   top-n \t accuracy\n",
      "       1 \t 0.03151862464183381\n",
      "       3 \t 0.09312320916905444\n",
      "       5 \t 0.12034383954154727\n",
      "      10 \t 0.16332378223495703\n",
      "      20 \t 0.20057306590257878\n",
      "      50 \t 0.21060171919770773\n",
      "     100 \t 0.21060171919770773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03151862464183381,\n",
       " 0.09312320916905444,\n",
       " 0.12034383954154727,\n",
       " 0.16332378223495703,\n",
       " 0.20057306590257878,\n",
       " 0.21060171919770773,\n",
       " 0.21060171919770773]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks_to_acc(results_random_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
